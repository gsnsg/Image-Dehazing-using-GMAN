{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport time\nimport glob\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.utils import make_grid\n\ntry:\n    from torchsummary import summary\nexcept:\n    !pip install torchsummary\n    from torchsummary import summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random crop the hazy image and its clear image\ndef random_crop(gt_image, hazy_image, target_shape = (224, 224)):\n    assert gt_image.shape[0] >= target_shape[0]\n    assert gt_image.shape[1] >= target_shape[1]\n    assert gt_image.shape[0] == hazy_image.shape[0]\n    assert gt_image.shape[1] == hazy_image.shape[1]\n    \n    x = np.random.randint(0, gt_image.shape[1] - target_shape[0])\n    y = np.random.randint(0, gt_image.shape[0] - target_shape[1])\n    \n    gt_image = gt_image[y : y + target_shape[0], x : x + target_shape[1]]\n    hazy_image = hazy_image[y : y + target_shape[0], x : x + target_shape[1]]\n    return hazy_image, gt_image\n\n\n# load image \ndef load_image(hazy_image_path, gt_image_path):\n    gt_image = Image.open(gt_image_path)\n    gt_image = np.array(gt_image, dtype=np.float32)\n    hazy_image = Image.open(hazy_image_path)\n    hazy_image = np.array(hazy_image, dtype=np.float32)\n    # Random Crop the image as suggested in paper\n    hazy_image, gt_image = random_crop(gt_image, hazy_image)\n    gt_image /= 255\n    hazy_image /= 255\n    \n    gt_img_tensor = torch.from_numpy(gt_image)\n    hazy_img_tensor = torch.from_numpy(hazy_image)\n    \n    return hazy_img_tensor.permute(2, 0, 1), gt_img_tensor.permute(2, 0, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gt_path = '../input/dehaze/clear_images/'\nhazy_path = '../input/dehaze/haze/'\n\n# Split dataset into train and validation splits\ndef get_data_splits(gt_images_path, hazy_images_path):\n    \n    gt_image_paths = list(glob.glob(gt_images_path + '*.jpg'))\n    hazy_image_paths = list(glob.glob(hazy_images_path + \"*.jpg\"))\n    \n    gt_images = []\n    hazy_images = []\n    \n    for gt_image in gt_image_paths:\n        img_name = gt_image.split('/')[-1].split('.')[0]\n        for hazy_image in hazy_image_paths:\n            if hazy_image.find(img_name) != -1:\n                gt_images.append(gt_image)\n                hazy_images.append(hazy_image)\n        \n    \n    total_images = len(gt_images)\n    \n    temp = list(zip(gt_images, hazy_images)) \n    np.random.shuffle(temp) \n    gt_images, hazy_images = zip(*temp)\n        \n    gt_images = list(gt_images)\n    hazy_images = list(hazy_images)\n    \n    \n    train_gt = gt_images[: int(total_images * 0.9)]\n    train_hazy = hazy_images[: int(total_images * 0.9)]\n    val_gt = gt_images[int(total_images * 0.9) : ]\n    val_hazy = hazy_images[int(total_images * 0.9) : ]\n    \n    \n    return {\n        'train_gt': train_gt,\n        'train_hazy': train_hazy,\n        'val_gt': val_gt,\n        'val_hazy': val_hazy\n    }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom Dataset with Hazy anf Ground Truth Images\nclass CustomDataset(Dataset):\n    def __init__(self, hazy_image_paths, gt_image_paths):\n        self.gt_image_paths = gt_image_paths\n        self.hazy_image_paths = hazy_image_paths\n        \n    def __getitem__(self, index):\n        return load_image(self.hazy_image_paths[index], self.gt_image_paths[index])\n\n    \n    def __len__(self):\n        return len(self.gt_image_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 35\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ndata_splits = get_data_splits(gt_path, hazy_path)\ntrain_dataset = CustomDataset(data_splits['train_hazy'], data_splits['train_gt'])\nval_dataset = CustomDataset(data_splits['val_hazy'], data_splits['val_gt'])\n\n# Training and Validation Data Loaders\n\ntrain_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\nval_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualBlock(nn.Module):\n\n    def __init__(self):\n        super(ResidualBlock, self).__init__()\n        self.res_b1 = self.get_res_block(2)\n        self.res_b2 = self.get_res_block(2)\n        self.res_b3 = self.get_res_block(3)\n        self.res_b4 = self.get_res_block(4)\n        self.relu = nn.ReLU(inplace = True)\n    \n    def get_res_block(self, block_size = 1, in_dim = 128, out_dim = 128):\n        layers = []\n        for i in range(block_size + 1):\n            layers.append(nn.Conv2d(in_dim, out_dim, 3, padding = 1))\n            if i != block_size:\n                layers.append(nn.ReLU(inplace = True))\n        return nn.Sequential(*layers)\n        \n        \n    \n    def forward(self, image):\n        output = self.res_b1(image)\n        res_b1_image = self.relu(image + output)\n        \n        output = self.res_b2(res_b1_image)\n        res_b2_image = self.relu(res_b1_image + output)\n        \n        output = self.res_b3(res_b2_image)\n        res_b3_image = self.relu(res_b2_image + output)\n        \n        output = self.res_b4(res_b3_image)\n        res_b4_image = res_b3_image + output\n        \n        return res_b4_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GMAN(nn.Module):\n    def __init__(self, in_dim = 3, hidden_dim = 64):\n        super(GMAN, self).__init__()\n        self.relu = nn.ReLU(inplace = True)\n        self.gman = nn.Sequential(\n            nn.Conv2d(in_dim, hidden_dim, 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(hidden_dim, hidden_dim, 3, padding = 1),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(hidden_dim, hidden_dim * 2, 3, padding = 1, stride = 2),\n            nn.ReLU(inplace = True),\n            nn.Conv2d(hidden_dim * 2, hidden_dim * 2, 3, padding = 1, stride = 2),\n            nn.ReLU(inplace = True),\n            ResidualBlock(),\n            nn.ReLU(inplace = True),\n            nn.ConvTranspose2d(hidden_dim * 2, hidden_dim, 2, stride = 2),\n            nn.ConvTranspose2d(hidden_dim, hidden_dim, 2, stride = 2),\n            nn.Conv2d(hidden_dim, hidden_dim, 3, padding = 1),\n            nn.Conv2d(hidden_dim, in_dim, 3, padding = 1),\n        )\n    \n    \n    def forward(self, image):\n        return self.relu(image + self.gman(image))\n    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_weights(m):\n    if type(m) == nn.Conv2d or type(m) == nn.ConvTranspose2d:\n        torch.nn.init.normal_(m.weight, mean=0.0, std=0.008)\n        m.bias.data.fill_(0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = GMAN().to(device)\nnet.apply(init_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image(hazy_image, gt_image, predicted_image):\n    \n    title = ['Hazy Image', 'Ground Truth Image', 'Predicted']\n    \n    plt.figure(figsize=(15, 15))\n    \n    \n    display_list = [\n                        hazy_image.cpu().permute(1, 2, 0).numpy(),\n                        gt_image.cpu().permute(1, 2, 0).numpy(),\n                        predicted_image.detach().cpu().permute(1, 2, 0).numpy()\n                   ]\n    \n    \n    for i in range(3):\n        plt.subplot(1, 3, i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n        \n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"n_epochs = 10\nopt = torch.optim.Adam(net.parameters(), lr = 0.0001)\ncriterion = nn.MSELoss()\n\n\nfor epoch in range(n_epochs):\n    total_train_loss = 0\n    total_val_loss = 0\n    start_time = time.time()\n    batch_no = 1\n    \n    print(f'Epoch {epoch + 1} started...')\n   \n    net.train()\n    for (hazy_images, gt_images) in train_dataloader:\n        curr_batch_size = hazy_images.size()\n        hazy_images = hazy_images.to(device)\n        gt_images = gt_images.to(device)\n        \n        outputs = net(hazy_images)\n        \n        train_loss = criterion(outputs, gt_images)\n        opt.zero_grad()\n        train_loss.backward()\n        opt.step()\n        total_train_loss += train_loss.item() \n        batch_no += 1\n      \n    \n    print(f'Total train loss: {total_train_loss}')\n    \n    if epoch % 2:\n        for(hazy_images, gt_images) in val_dataloader:\n            with torch.no_grad():\n                hazy_images = hazy_images.to(device)\n                gt_images = gt_images.to(device)\n                outputs = net(hazy_images)\n\n                show_image(hazy_images[0], gt_images[0], outputs[0])\n\n\n                val_loss = criterion(outputs, gt_images)\n                total_val_loss += val_loss.item() \n        \n        print(f'Total validation loss: {total_val_loss}')\n    \n    end_time = time.time()\n    \n    print(f'Epoch {epoch + 1} ended, time taken: {end_time - start_time}s')\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net.state_dict(), 'state_dict_model.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}